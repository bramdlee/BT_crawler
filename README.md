# 데이터 크롤러 만들기 속성 스터디

커뮤니티에서 넘쳐나는 데이터를 모두 읽기는 사실상 불가능한 현실입니다.<br>
읽고 생각할 시간도 부족한데 모든 커뮤니티를 일일히 들어가서 보는 시간조차 아껴야 하는 상황입니다.

블록체인 타이거 팀에 보다 활발한 활동을 위해서 웹서칭의 시간을 줄여주는 방도가 필요해 봅니다.<bR>
여러분의 소중한 시간을 줄여주기 위해 Web Crawling bot을 만들기 위한 속성 스터디를 계획해보았습니다.

첫번째 러닝 코스는 다음과 같습니다.

- Python 기초문법(코드아카데미 python 코스로 대체)
- Jupyter notebook 설치 및 가동하기.
- Anaconda CLI 사용하기(Jupyter notebook 환경설정).
- Python requests 라이브러리 사용하여 웹페이지 불러오기.
- Python BeautifulSoup 라이브러리로 웹페이지 파싱하기.
- 웹브라우저 개발자 모드를 통한 HTML 구조의 이해, 기초 소개.
- ~~Python 정규식 사용하기.~~
- Python Pandas 라이브러리 사용하여 데이터 테이블 만들어 보기.
- ~~Twitter API를 활용하여 데이터 수집하기.~~
**9월 21일 차 진행 과정**
커뮤니티에서 발생하는 모든 글들을 한 곳에 모을 수 있습니다.

두번째 러닝코스로, 크롤링 봇을 쉬지 않게 만드는 과정입니다.
~~24시간 수집 및 분석을 위해서는 VPC가 필수 입니다.~~

- 텔레그램 NOTICE 봇 만들어보기. **10월 12일(목) 재개**
- ~~아마존 ec2 무료 인스턴스 띄우기.~~
- ~~아마존 ec2 인스턴스에 Jupyter notebook 설치 및 가동하기.~~
- ~~mysql 서버 구축 및 데이터 입출력 하기.~~
- python 크롤링 봇을 띄워 DB에 데이터 저장하기.
- Article 요약 라이브러리 사용하여 줄여보기.
- NLTK 라이브러리를 사용하여 데이터 분석하기.
- 텔레그램 NOTICE 봇 만들어보기.

추가적으로 알아두면 좋은 사이드 코스는
- git 사용법.
- github을 통해 코드 공유해보기.
- docker 사용하기.

Python 프로그래밍을 처음 접할때 고전하는 것이 개발환경을 세팅하는데 있습니다.
그래서 보통은 파이썬 강의를 할때 docker를 사용함으로써 개발환경을 통일화 시키고 시작하게 되는데.
이 또한 docker를 배워야 하는 부담감이 있습니다. 하지만 docker 배워둠으로써 시스템 이전이나 확장할때 유용하기 때문에 고려해봐야 할 요소중에 하나입니다.

스터디원이 2~3명이라면 제가 개발환경을 하나씩 세팅해 드리면서 진행 할 수 있습니다만,
4명이 넘어가면 virtual box로 리눅스 가상환경에 docker를 띄워서 진행 하도록 하겠습니다.
첫번째 러닝코스 진행시간만 6시간 예상됩니다(기초문법, Twitter API 사용제외).

블록체인타이거팀 화이팅!
